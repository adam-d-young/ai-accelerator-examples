fullnameOverride: qwen2-1.5b

# Force CPU-only deployment
deploymentMode: RawDeployment
runtimeType: cpu

model:
  uri: oci://quay.io/redhat-ai-services/modelcar-catalog:qwen2-1.5b-instruct
  modelNameOverride: qwen2-1.5b

# CPU-friendly configuration
resources:
  limits:
    cpu: "4"
    memory: "8Gi"
  requests:
    cpu: "2"
    memory: "4Gi"

# Explicitly disable GPU/accelerator
accelerator:
  enabled: false

# Override ServingRuntime to use CPU version
servingRuntime:
  name: vllm-cpu
  image: quay.io/modh/vllm:v0.4.2
  
# CPU-specific vLLM arguments
vllm:
  args:
    - --model
    - qwen2-1.5b
    - --port
    - "8080"
    - --tensor-parallel-size
    - "1"
    - --device
    - cpu